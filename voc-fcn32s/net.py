import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import *
from tensorflow.keras.applications.vgg16 import *




# RTX 3070 Set Session. ----------------------------------------
cfg = tf.compat.v1.ConfigProto()
cfg.gpu_options.allow_growth = True
sess = tf.compat.v1.Session(config=cfg)
# --------------------------------------------------------------

def conv_relu(nout=4096, ks=3, stride=(1,1), pad='valid'):
    conv = Conv2D(filters=nout, kernel_size=ks, stride=stride,
        num_output=nout, padding=pad,
        param=[dict(lr_mult=1, decay_mult=1), dict(lr_mult=2, decay_mult=0)])
    return conv, ReLU(conv, in_place=True)


def max_pool(bottom, ks=2, stride=2):
    # return L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride)
    return MaxPooling2D(bottom, pool_size=(ks, ks), strides=stride)



def fcn(image_size, ch_in=3, n_classes=3):
    inputs = Input(shape=(*image_size, ch_in), name='input')

    # Building a pre-trained VGG-16 feature extractor (i.e., without the final FC layers)
    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=inputs)
    # Recovering the feature maps generated by each of the 3 final blocks:
    pool3 = vgg16.get_layer('block3_pool').output
    pool4 = vgg16.get_layer('block4_pool').output
    pool5 = vgg16.get_layer('block5_pool').output   # Feature Extractor's Output.

    # # the base net --VGG16
    # data, label = encoder(input_height=224,
    #                       input_width=224,
    #                       channels=3)
    # conv1_1, relu1_1 = conv_relu(data, 64, pad=100)
    # conv1_2, relu1_2 = conv_relu(relu1_1, 64)
    # pool1 = max_pool(relu1_2)
    #
    # conv2_1, relu2_1 = conv_relu(pool1, 128)
    # conv2_2, relu2_2 = conv_relu(relu2_1, 128)
    # pool2 = max_pool(relu2_2)
    #
    # conv3_1, relu3_1 = conv_relu(pool2, 256)
    # conv3_2, relu3_2 = conv_relu(relu3_1, 256)
    # conv3_3, relu3_3 = conv_relu(relu3_2, 256)
    # pool3 = max_pool(relu3_3)
    #
    # conv4_1, relu4_1 = conv_relu(pool3, 512)
    # conv4_2, relu4_2 = conv_relu(relu4_1, 512)
    # conv4_3, relu4_3 = conv_relu(relu4_2, 512)
    # pool4 = max_pool(relu4_3)
    #
    # conv5_1, relu5_1 = conv_relu(pool4, 512)
    # conv5_2, relu5_2 = conv_relu(relu5_1, 512)
    # conv5_3, relu5_3 = conv_relu(relu5_2, 512)
    # pool5 = max_pool(relu5_3)

    # fully conv -------------------------------------------------------------------------------------------------------
    # Replacing VGG dense layers by convolutions:

    x = Conv2D(filters=4096, kernel_size=7, padding='valid')(pool5)               # Dense-1
    x = ReLU()(x)
    x = Dropout(0.5)(x)

    x = Conv2D(filters=4096, kernel_size=1, padding='valid')(x)                   # Dense-2
    x = ReLU()(x)
    x = Dropout(0.5)(x)

    score_fr = Conv2D(filters=n_classes, kernel_size=1, padding='valid')(x)       # Dense-3

    upscore = Conv2DTranspose(filters=n_classes, kernel_size=64, strides=32, padding='same')(score_fr)

    outputs = Softmax()(upscore)

    fcn_model = Model(inputs, outputs)
    return fcn_model









    #
    #
    # fc6, relu6 = conv_relu(pool5, 4096, ks=7, pad='valid')                      # Dense Layer1
    # drop6 = Dropout(relu6, dropout_ratio=0.5, in_place=True)
    # fc7, relu7 = conv_relu(drop6, 4096, ks=1, pad='valid')                      # Dense Layer2
    # drop7 = Dropout(relu7, dropout_ratio=0.5, in_place=True)
    # score_fr = Conv2D(drop7, num_output=21, kernel_size=1, pad=0,    # Dense Layer3 - Predict Layer
    #     param=[dict(lr_mult=1, decay_mult=1), dict(lr_mult=2, decay_mult=0)])
    # upscore = Deconvolution(score_fr,
    #     convolution_param=dict(num_output=21, kernel_size=64, stride=32,
    #         bias_term=False),
    #     param=[dict(lr_mult=0)])
    # score = crop(upscore, data)
    # score = L.Cropping2D(cropping=upscore, data_format=)
    # loss = L.SoftmaxWithLoss(score, label,
    #         loss_param=dict(normalize=False, ignore_label=255))



    return